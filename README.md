# ğŸ“œ Scraping de Leyes de la Provincia de Buenos Aires

Este proyecto permite realizar **web scraping** de la base de datos de normas jurÃ­dicas de la Provincia de Buenos Aires.
Utiliza **Python, asyncio y aiohttp** para realizar mÃºltiples solicitudes en paralelo, extrayendo informaciÃ³n de hasta **15.520 leyes** de manera eficiente. ğŸš€

## âš¡ CaracterÃ­sticas

- ğŸ”„ **Scraping AsÃ­ncrono**: Utiliza `aiohttp` y `asyncio` para obtener datos de manera paralela.
- ğŸ“‘ **Almacenamiento en CSV**: Guarda los datos extraÃ­dos en un archivo `leyes.csv` con el siguiente formato:

  ```csv
  numero_ley,resumen,url
  1000,"DescripciÃ³n de la ley 1000","https://normas.gba.gob.ar/ar-b/ley/1875/1000/12036"
  ```

- ğŸŒ **ExtracciÃ³n de Datos Clave**:
  - NÃºmero de ley ğŸ“Œ
  - Resumen ğŸ“
  - URL ğŸ”—
- ğŸš¦ **Manejo de errores**: Ignora leyes inexistentes y maneja solicitudes fallidas.

## ğŸ›  InstalaciÃ³n y Uso

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/leodelosrios/scraping-leyes-prov-bs-as.git
cd scraping-leyes-prov-bs-as
```

### 2ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Ejecutar el script

```bash
python scraping.py
```

## ğŸ“¢ Ejemplo de salida en consola

Cada vez que se encuentra una ley, se muestra en la terminal:

```bash
Ley encontrada: 1000
Ley encontrada: 1024
Ley encontrada: 1100
...
```

## ğŸ— TecnologÃ­as Utilizadas

- **Python 3** ğŸ
- **aiohttp** (para solicitudes HTTP asÃ­ncronas) âš¡
- **asyncio** (para ejecutar tareas en paralelo) ğŸ”„
- **BeautifulSoup** (para extraer datos del HTML) ğŸ—
- **CSV** (para almacenar los datos extraÃ­dos) ğŸ“‚

## ğŸ“Œ Contacto y Contribuciones

ğŸ“§ Contacto: [GitHub](https://github.com/leodelosrios)

Â¡Gracias por tu interÃ©s en este proyecto! ğŸ˜Š
